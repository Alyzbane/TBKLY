E:\venv\ml\Lib\site-packages\transformers\models\vit\modeling_vit.py:261: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\aten\src\ATen\native\transformers\cuda\sdp_utils.cpp:455.)
  context_layer = torch.nn.functional.scaled_dot_product_attention(
***** train metrics *****
  epoch                    =        1.0
  total_flos               = 87761127GF
  train_loss               =     0.7992
  train_runtime            = 0:25:12.73
  train_samples_per_second =      0.804
  train_steps_per_second   =      0.025
***** eval metrics *****
  epoch                   =        1.0
  eval_accuracy           =     0.8758
  eval_loss               =      0.345
  eval_runtime            = 0:01:13.49
  eval_samples_per_second =      2.082
  eval_steps_per_second   =      0.272